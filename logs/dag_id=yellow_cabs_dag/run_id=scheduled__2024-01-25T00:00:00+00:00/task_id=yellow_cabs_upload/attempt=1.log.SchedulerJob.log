[2024-01-26T20:02:50.500+0000] {scheduler_job_runner.py:1586} WARNING - Marking task instance <TaskInstance: yellow_cabs_dag.yellow_cabs_upload scheduled__2024-01-25T00:00:00+00:00 [queued]> stuck in queued as failed. If the task instance has available retries, it will be retried.
[2024-01-26T20:02:50.639+0000] {scheduler_job_runner.py:781} ERROR - Executor reports task instance <TaskInstance: yellow_cabs_dag.yellow_cabs_upload scheduled__2024-01-25T00:00:00+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
[2024-01-29T18:42:11.616+0000] {scheduler_job_runner.py:1766} ERROR - Detected zombie job: {'full_filepath': '/opt/airflow/dags/yellow_cabs_project.py', 'processor_subdir': '/opt/airflow/dags', 'msg': "{'DAG Id': 'yellow_cabs_dag', 'Task Id': 'yellow_cabs_upload', 'Run Id': 'scheduled__2024-01-25T00:00:00+00:00', 'Hostname': 'd8c0631e3b56', 'External Executor Id': '1956f5ce-ab44-4d51-82a6-f405a0046673'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0xffff744134c0>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
[2024-01-29T18:42:26.839+0000] {scheduler_job_runner.py:1766} ERROR - Detected zombie job: {'full_filepath': '/opt/airflow/dags/yellow_cabs_project.py', 'processor_subdir': '/opt/airflow/dags', 'msg': "{'DAG Id': 'yellow_cabs_dag', 'Task Id': 'yellow_cabs_upload', 'Run Id': 'scheduled__2024-01-25T00:00:00+00:00', 'Hostname': 'd8c0631e3b56', 'External Executor Id': '1956f5ce-ab44-4d51-82a6-f405a0046673'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0xffff74474130>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
